\section{Evaluation}
Coming to a conclusion of how accurate an estimation or analysis system is of course the most important thing. If a system is inaccurate and produces incorrect results then it is a learning exercise at best and a useless waste of time at worst. Evaluating this system is done by determining the percentage of sentiment estimations that were accurate.

Evaluation of the accuracy of the sentiment estimations for this data is actually incredibly simple. Because each review has a user-input rating already associated with it, all that must be done is to compare the estimated positive or negative sentiment with the given value.

Results for this system will be primarily compared to Pang and Lee's results mentioned earlier in the document, as our methods both involve the standard machine learning catigorization algorithms. Using feature presence, as this project does, with a list of 16165 features, they were able to achieve 81\% accuracy with the Naive Bayes method, and 82.9\% accuracy with the support vector machine method. 
